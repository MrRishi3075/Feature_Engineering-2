{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b2349e9-8282-4153-84f9-e059aa6908c6",
   "metadata": {},
   "source": [
    "### Q1. What is the Filter method in feature selection, and how does it work?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41b6435-c0e7-46ef-89c0-94267299947e",
   "metadata": {},
   "source": [
    "* The filter method is one of the techniques used in feature selection, which is a process of choosing a subset of relevant and important features from a larger set of features in a dataset. The filter method evaluates the relevance of features based on statistical measures and does not involve training a machine learning model.\n",
    "\n",
    "##### Here's how the filter method generally works:\n",
    "\n",
    "###### Feature Ranking:\n",
    "\n",
    "* Calculate a statistical measure (e.g., correlation, mutual information, chi-squared, etc.) for each feature in isolation, without considering the target variable.\n",
    "* Rank the features based on these individual scores. Features with higher scores are considered more important.\n",
    "\n",
    "###### Selection Threshold:\n",
    "\n",
    "* Set a threshold for the feature scores.\n",
    "* Features with scores above this threshold are retained, while those below the threshold are discarded.\n",
    "\n",
    "###### Subset Selection:\n",
    "\n",
    "* Form a subset of the original features using the selected features based on the threshold.\n",
    "\n",
    "* The primary advantage of the filter method is its simplicity and computational efficiency. Since it doesn't involve training a model, it can be applied quickly to large datasets. However, the filter method has some limitations. It doesn't consider the interactions between features, and it might discard relevant features if their importance is only evident in combination with other features.\n",
    "\n",
    "###### Common statistical measures used in the filter method include:\n",
    "\n",
    "1. Correlation: Measures the linear relationship between two variables. Features highly correlated with the target variable are considered more relevant.\n",
    "\n",
    "2. Mutual Information: Measures the amount of information one variable provides about another variable. It is particularly useful for identifying nonlinear relationships.\n",
    "\n",
    "3. Chi-squared: Often used for categorical variables, it measures the independence between variables.\n",
    "\n",
    "4. ANOVA (Analysis of Variance): Used to compare the means of different groups. It is suitable for regression problems with a categorical target variable.\n",
    "\n",
    "###### It's worth noting that the choice of the filter method and the specific statistical measure depends on the nature of the data and the problem at hand. Different measures are suitable for different types of data and relationships.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a2db18-0c6d-4697-a940-3c41eed8b31e",
   "metadata": {},
   "source": [
    "\n",
    "### Q2. How does the Wrapper method differ from the Filter method in feature selection?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e583dbad-3b4d-4d7d-98a9-695c319cabde",
   "metadata": {},
   "source": [
    "#### The Wrapper method and the Filter method are both techniques for feature selection, but they differ in their approach and how they evaluate the relevance of features. Here are the key differences between the Wrapper and Filter methods:\n",
    "\n",
    "## 1. Evaluation Criteria:\n",
    "#### Filter Method:\n",
    "\n",
    "* The filter method evaluates the relevance of features based on statistical measures or heuristics without involving a machine learning model.\n",
    "* Features are ranked or selected using criteria such as correlation, mutual information, chi-squared, etc.\n",
    "\n",
    "#### Wrapper Method:\n",
    "\n",
    "* The wrapper method involves training a machine learning model to evaluate the performance of different subsets of features.\n",
    "* It uses a performance metric (e.g., accuracy, precision, recall, F1 score) obtained from the model's performance on a validation set to assess the quality of feature subsets.\n",
    "\n",
    "## 2. Model Involvement:\n",
    "#### Filter Method:\n",
    "\n",
    "* No machine learning model is trained during the feature selection process. The selection is based solely on statistical measures.\n",
    "\n",
    "#### Wrapper Method:\n",
    "\n",
    "* Involves training a machine learning model multiple times, each time with a different subset of features.\n",
    "* The model's performance is used as the criterion to determine the relevance of features.\n",
    "\n",
    "## 3. Computational Cost:\n",
    "#### Filter Method:\n",
    "\n",
    "* Generally computationally less expensive than the wrapper method since it doesn't involve training a model.\n",
    "\n",
    "#### Wrapper Method:\n",
    "\n",
    "* Can be computationally expensive, especially if the model needs to be trained multiple times for different subsets of features.\n",
    "\n",
    "## 4. Interactions Between Features:\n",
    "#### Filter Method:\n",
    "\n",
    "* Does not consider interactions between features. Each feature is evaluated independently of others.\n",
    "#### Wrapper Method:\n",
    "\n",
    "* Can capture interactions between features, as the model is trained on different combinations of features.\n",
    "## 5. Search Strategy:\n",
    "#### Filter Method:\n",
    "\n",
    "* Typically employs a univariate analysis, evaluating each feature independently.\n",
    "#### Wrapper Method:\n",
    "\n",
    "* Employs a search strategy, which can be forward selection, backward elimination, or exhaustive search, to explore different combinations of features.\n",
    "## 6. Suitability:\n",
    "#### Filter Method:\n",
    "\n",
    "* Suitable for datasets with a large number of features, as it is computationally efficient.\n",
    "#### Wrapper Method:\n",
    "\n",
    "* More suitable for smaller datasets with fewer features due to the computational cost of training the model for each subset.\n",
    "## 7. Overfitting:\n",
    "#### Filter Method:\n",
    "\n",
    "* Less prone to overfitting, as it doesn't involve training a model on the entire dataset.\n",
    "\n",
    "#### Wrapper Method:\n",
    "\n",
    "* More prone to overfitting, especially if the model selection process is not properly controlled.\n",
    "\n",
    "##### In summary, while the filter method relies on statistical measures to evaluate feature relevance independently, the wrapper method incorporates the use of a machine learning model and evaluates features based on their impact on model performance. The choice between these methods depends on factors such as the dataset size, computational resources, and the specific goals of feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e3c02a-7c2f-489c-aa54-9ce871af6267",
   "metadata": {},
   "source": [
    "\n",
    "### Q3. What are some common techniques used in Embedded feature selection methods?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b228f4c7-4ec2-4c08-a770-698ed2a62500",
   "metadata": {},
   "source": [
    "#### 1. LASSO (Least Absolute Shrinkage and Selection Operator):\n",
    "\n",
    "* LASSO is a linear regression technique that adds a penalty term to the standard regression objective function, encouraging the model to produce sparse coefficients. This effectively performs feature selection during the training process.\n",
    "\n",
    "#### 2. Ridge Regression:\n",
    "\n",
    "* Similar to LASSO, Ridge Regression adds a penalty term to the regression objective function. While LASSO tends to produce sparse solutions (some coefficients become exactly zero), Ridge Regression shrinks the coefficients toward zero, encouraging but not enforcing sparsity.\n",
    "\n",
    "#### 3. Elastic Net:\n",
    "\n",
    "* Elastic Net is a hybrid of LASSO and Ridge Regression, combining their penalty terms. It provides a balance between feature selection (as in LASSO) and the ability to handle correlated features (as in Ridge Regression).\n",
    "\n",
    "#### 4. Decision Trees (with Feature Importance):\n",
    "\n",
    "* Decision trees and ensemble methods (e.g., Random Forests, Gradient Boosting) can provide a measure of feature importance during the training process. Features that contribute more to reducing impurity or error are considered more important.\n",
    "\n",
    "#### 5. Recursive Feature Elimination (RFE):\n",
    "\n",
    "* RFE is a technique where a model is trained, and then the least important feature (or features) is removed. This process is repeated until the desired number of features is reached. The importance of features is determined by the model's coefficients or other relevant criteria.\n",
    "\n",
    "#### 6. Regularized Linear Models (e.g., Regularized Logistic Regression):\n",
    "\n",
    "* Regularized linear models, similar to LASSO in regression, can be applied to classification tasks (e.g., logistic regression with L1 regularization). This induces sparsity in the model coefficients and, consequently, performs feature selection.\n",
    "\n",
    "#### 7. XGBoost and LightGBM Feature Importance:\n",
    "\n",
    "* Gradient boosting algorithms like XGBoost and LightGBM have built-in methods for calculating feature importance. These methods consider how often a feature is used in decision trees and how much it contributes to the model's performance.\n",
    "\n",
    "#### 8. Deep Learning with Dropout:\n",
    "\n",
    "* In deep learning models, dropout is a regularization technique where randomly selected neurons are ignored during training. This can be interpreted as a form of feature selection, as certain neurons (and hence, features) are excluded during each training iteration.\n",
    "\n",
    "#### 9. Sparse Autoencoders:\n",
    "\n",
    "###### Autoencoders are neural network architectures used for unsupervised learning. When designed to have a sparse hidden layer, autoencoders can be used for feature selection, as only a subset of neurons will be activated for a given input.\n",
    "##### These embedded feature selection methods are advantageous because they consider feature relevance within the context of the model training process. The choice of method depends on the specific characteristics of the data and the modeling task at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197072b5-deba-4a0f-9219-fd860c48e0a9",
   "metadata": {},
   "source": [
    "\n",
    "### Q4. What are some drawbacks of using the Filter method for feature selection?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd4b9d8-95a6-4497-8d91-e3968a0c3b77",
   "metadata": {},
   "source": [
    "#### While the filter method for feature selection has its advantages, it also comes with certain drawbacks. Here are some of the limitations associated with the filter method:\n",
    "\n",
    "#### 1. Ignores Feature Interactions:\n",
    "\n",
    "* The filter method evaluates features independently and does not take into account potential interactions between features. In many real-world scenarios, the importance of a feature may depend on its interaction with other features. The filter method may miss such dependencies.\n",
    "\n",
    "#### 2. Limited to Univariate Analysis:\n",
    "\n",
    "* Most filter methods perform univariate analysis, considering each feature in isolation. This approach may not capture the joint effects or dependencies among features. Multivariate relationships and interactions may be crucial for accurately representing the underlying patterns in the data.\n",
    "\n",
    "#### 3. Insensitive to Model Performance:\n",
    "\n",
    "* Filter methods are not directly tied to the performance of a specific machine learning model. The selected features are based solely on statistical measures and may not necessarily lead to improved model performance. The ultimate goal of feature selection is often to enhance model performance, which the filter method may not guarantee.\n",
    "\n",
    "#### 4. Doesn't Adapt to Model Complexity:\n",
    "\n",
    "* The filter method does not adapt to the complexity of the underlying model. It may select features that are statistically correlated with the target variable but may not be the most relevant for a specific predictive model. More sophisticated models may require different subsets of features.\n",
    "\n",
    "#### 5. Sensitivity to Feature Scaling:\n",
    "\n",
    "* Some filter methods, such as correlation-based methods, can be sensitive to the scale of the features. Features with larger scales may dominate the selection process, even if they are not inherently more informative. Normalizing or standardizing features may be necessary to address this issue.\n",
    "\n",
    "#### 6. Ignores Model Learning Dynamics:\n",
    "\n",
    "* The filter method does not consider the learning dynamics of the model. Certain features may become more or less important as the model learns, and the filter method may not adapt to these changes over the course of model training.\n",
    "\n",
    "#### 7. Limited to Feature Ranking:\n",
    "\n",
    "* Many filter methods provide a ranked list of features based on their individual scores, but they do not provide information on the optimal number of features to select. Deciding on the appropriate number of features can be a challenge.\n",
    "\n",
    "#### 8. Not Optimized for Specific Models:\n",
    "\n",
    "* Filter methods are generic and do not take into consideration the characteristics of specific machine learning models. Different models may have different feature requirements, and the filter method does not optimize feature selection for a particular modeling algorithm.\n",
    "\n",
    "##### Despite these drawbacks, the filter method remains a valuable and computationally efficient tool for preliminary feature selection, especially in scenarios where the dataset is large and a quick initial analysis is needed. However, it is often beneficial to complement filter methods with other techniques, such as wrapper methods or embedded methods, to address some of these limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e72e3d-2bd8-4654-82cb-853189b799ca",
   "metadata": {},
   "source": [
    "\n",
    "### Q5. In which situations would you prefer using the Filter method over the Wrapper method for feature selection?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ea390f-d114-4a45-891b-39c2c8ed10f4",
   "metadata": {},
   "source": [
    "#### The choice between the Filter method and the Wrapper method for feature selection depends on various factors, including the characteristics of the dataset, computational resources, and the goals of the analysis. Here are some situations in which you might prefer using the Filter method over the Wrapper method:\n",
    "\n",
    "##### 1. Large Datasets:\n",
    "\n",
    "* Filter methods are computationally efficient and are well-suited for large datasets with a high number of features. When dealing with a vast amount of data, the computational cost of repeatedly training a model, as done in the Wrapper method, can be prohibitive. Filter methods, which analyze features independently of each other, can provide a quick and scalable solution.\n",
    "\n",
    "##### 2. Preliminary Feature Analysis:\n",
    "\n",
    "* In the early stages of a project, especially during exploratory data analysis, a quick assessment of feature relevance may be required. Filter methods are suitable for providing an initial feature ranking or subset without the need for extensive model training.\n",
    "\n",
    "##### 3. Noisy or Redundant Features:\n",
    "\n",
    "* Filter methods can be effective in identifying and filtering out noisy or redundant features. Features with low relevance to the target variable or high correlations with other features can be easily identified using filter techniques.\n",
    "\n",
    "##### 4. Understanding Feature Importance:\n",
    "\n",
    "* If the primary goal is to understand the importance of each feature individually, rather than considering their interactions, filter methods are appropriate. Filter methods provide a clear ranking of features based on specific statistical measures, helping to identify the most influential features in isolation.\n",
    "\n",
    "##### 5. Feature Preprocessing:\n",
    "\n",
    "* Filter methods can be used as a preprocessing step before applying more computationally expensive feature selection techniques. By quickly narrowing down the feature set, filter methods can reduce the search space for subsequent wrapper or embedded methods.\n",
    "\n",
    "##### 6. No Need for Model Training:\n",
    "\n",
    "* If the primary goal is to select features without training a predictive model, the Filter method is a suitable choice. In some cases, the focus may be on identifying features that have a strong univariate relationship with the target variable, without building a complex predictive model.\n",
    "\n",
    "##### 7. Statistical Independence:\n",
    "\n",
    "* When the assumption of feature independence is reasonable or when considering features independently aligns with the problem domain, filter methods can be appropriate. For example, in certain statistical analyses or experimental settings, features may be assumed to be unrelated.\n",
    "\n",
    "##### 8. Less Risk of Overfitting:\n",
    "\n",
    "* Filter methods are less prone to overfitting because they do not involve training a model on the entire dataset. This can be advantageous, especially in situations where the risk of overfitting is a concern.\n",
    "\n",
    "*  * In summary, the Filter method is preferred in situations where a quick and computationally efficient feature selection approach is needed, especially in the early stages of analysis or when dealing with large datasets. However, it's important to recognize that the choice between filter and wrapper methods is not mutually exclusive, and a combination of both may be employed for a more comprehensive feature selection strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c2e3fa-be9f-4370-93fb-f676974c994c",
   "metadata": {},
   "source": [
    "\n",
    "### Q6. In a telecom company, you are working on a project to develop a predictive model for customer churn. You are unsure of which features to include in the model because the dataset contains several different ones. Describe how you would choose the most pertinent attributes for the model using the Filter Method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d257559c-d9c7-4ec4-8887-793b7fbcfcf3",
   "metadata": {},
   "source": [
    "* * When working on a predictive model for customer churn in a telecom company, you can use the Filter method to choose the most pertinent attributes for the model. Here's a step-by-step guide on how you might approach this using the Filter method:\n",
    "\n",
    "1. Understand the Problem:\n",
    "\n",
    "* * Gain a thorough understanding of the problem you are trying to solve. In the context of customer churn prediction, identify the target variable (churn or no-churn) and the features that may influence customer behavior.\n",
    "\n",
    "2. Data Exploration:\n",
    "\n",
    "* * Perform exploratory data analysis (EDA) to understand the distribution of features, identify missing values, and analyze basic statistics. This step will help you get a sense of the data and its characteristics.\n",
    "\n",
    "3. Define Evaluation Metric:\n",
    "\n",
    "* * Clearly define the evaluation metric that you will use to assess the performance of your predictive model. Common metrics for binary classification problems like churn prediction include accuracy, precision, recall, F1 score, and area under the receiver operating characteristic (ROC) curve.\n",
    "\n",
    "4. Feature Scaling:\n",
    "\n",
    "* * Ensure that the features are appropriately scaled, especially if you are using filter methods that are sensitive to the scale of features, such as correlation-based methods.\n",
    "\n",
    "5. Choose Filter Method:\n",
    "\n",
    "* * Select a filter method based on the characteristics of your data. Common statistical measures used in the filter method for classification problems include correlation, mutual information, chi-squared, and Information Gain. The choice may depend on whether your features are continuous or categorical.\n",
    "\n",
    "6. Calculate Feature Scores:\n",
    "\n",
    "* * Calculate the selected statistical measure for each feature with respect to the target variable (churn). This will give you a score or ranking for each feature based on its relevance to the target variable.\n",
    "\n",
    "7. Set a Threshold:\n",
    "\n",
    "* * Set a threshold for feature selection. Features with scores above this threshold will be considered relevant, while those below will be discarded. The threshold can be determined based on domain knowledge, experimentation, or by using statistical criteria.\n",
    "\n",
    "8. Feature Selection:\n",
    "\n",
    "* * Create a subset of features that pass the threshold. These selected features will be used for building the predictive model.\n",
    "\n",
    "9. Validate Results:\n",
    "\n",
    "* * Validate the selected features by analyzing their importance and potential impact on the model's performance. You may also want to perform cross-validation to ensure the stability and generalizability of the results.\n",
    "\n",
    "10. Iterate if Necessary:\n",
    "\n",
    "* * If the initial model performance is not satisfactory, consider iterating the process by adjusting the threshold or trying different filter methods. You can also explore complementary feature selection methods, such as wrapper methods or embedded methods.\n",
    "\n",
    "11. Build and Evaluate Predictive Model:\n",
    "\n",
    "* * Finally, build a predictive model using the selected features and evaluate its performance on a separate validation set using the predefined evaluation metric.\n",
    "\n",
    "###### Remember that the choice of the filter method and specific statistical measure depends on the characteristics of your data. Additionally, it's advisable to complement filter methods with other feature selection techniques for a more comprehensive analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc265f3e-9472-40fe-9d75-bae1208bdec0",
   "metadata": {},
   "source": [
    "\n",
    "### Q7. You are working on a project to predict the outcome of a soccer match. You have a large dataset with many features, including player statistics and team rankings. Explain how you would use the Embedded method to select the most relevant features for the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3adacc-d3d8-4fd6-9874-747c1c9b249e",
   "metadata": {},
   "source": [
    "#### When working on a project to predict the outcome of a soccer match using a large dataset with many features, including player statistics and team rankings, you can employ embedded methods to select the most relevant features during the model training process. Embedded methods integrate feature selection directly into the learning algorithm. Here's a step-by-step guide on how you might approach this:\n",
    "\n",
    "1. Data Preprocessing:\n",
    "\n",
    "* Start by preprocessing the dataset. Handle missing values, encode categorical variables, and standardize or normalize numerical features if necessary. Ensure that the data is in a suitable format for the machine learning algorithm you plan to use.\n",
    "\n",
    "2. Define Target Variable:\n",
    "\n",
    "* Clearly define the target variable for your prediction task. In the context of predicting soccer match outcomes, the target variable might be a binary variable indicating whether the home team wins (1), loses (0), or the match ends in a draw.\n",
    "\n",
    "3. Choose a Predictive Model:\n",
    "\n",
    "* Select a predictive model suitable for the classification task of predicting match outcomes. Common models for this type of task include logistic regression, decision trees, random forests, or gradient boosting algorithms like XGBoost.\n",
    "\n",
    "4. Select Embedded Method:\n",
    "\n",
    "* Choose an embedded feature selection method that is compatible with the chosen predictive model. Many machine learning algorithms have built-in mechanisms for feature selection. For example, in the case of decision trees, random forests, and XGBoost, feature importance can be extracted during or after the training process.\n",
    "\n",
    "5. Train the Model:\n",
    "\n",
    "* Train the selected predictive model using the entire dataset. During the training process, the algorithm will automatically assign importance scores to each feature based on their contribution to the model's performance.\n",
    "\n",
    "6. Extract Feature Importance:\n",
    "\n",
    "##### If using decision trees, random forests, or gradient boosting algorithms, you can extract feature importance scores after the model is trained. These scores indicate the relative importance of each feature in making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62602c16-f3b6-4330-88b6-67f9a0e10b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Generate a synthetic dataset for illustration\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=8, n_redundant=2, random_state=42)\n",
    "\n",
    "# Create a DataFrame\n",
    "columns = [f'feature_{i}' for i in range(X.shape[1])]\n",
    "df = pd.DataFrame(X, columns=columns)\n",
    "df['target'] = y\n",
    "\n",
    "# Replace 'target' with the actual name of your target variable column\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize or normalize the features if needed\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9093efc7-96af-478f-8ef0-ed90c3f5e754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example using XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "# Assuming X_train and y_train are your feature and target variable arrays\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Extract feature importance scores\n",
    "feature_importance = model.feature_importances_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc89cd66-fa5c-48bd-b5c5-51db04203d51",
   "metadata": {},
   "source": [
    "7. Set a Threshold or Rank Features:\n",
    "\n",
    "* Depending on your preference or requirements, you can set a threshold to retain only features with importance scores above a certain value. Alternatively, you can rank features based on their importance scores.\n",
    "\n",
    "8. Feature Selection:\n",
    "\n",
    "* Create a subset of features that pass the threshold or select the top-ranked features. This subset will be used for building the final predictive model.\n",
    "\n",
    "9. Model Evaluation:\n",
    "\n",
    "* Evaluate the performance of your predictive model using the selected features. Utilize appropriate evaluation metrics such as accuracy, precision, recall, F1 score, or area under the ROC curve.\n",
    "\n",
    "10. Iterate and Tune:\n",
    "\n",
    "* If necessary, iterate through the process, adjusting parameters, thresholds, or considering alternative embedded methods. Fine-tune the model to improve performance.\n",
    "\n",
    "* * Using embedded methods for feature selection in the context of predicting soccer match outcomes allows the model to automatically identify the most relevant features during the training process. It's important to interpret the feature importance scores and validate the model's performance on a separate test set to ensure its generalizability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e3d64d-090d-4fae-b0ad-3b002619a04f",
   "metadata": {},
   "source": [
    "\n",
    "### Q8. You are working on a project to predict the price of a house based on its features, such as size, location, and age. You have a limited number of features, and you want to ensure that you select the most important ones for the model. Explain how you would use the Wrapper method to select the best set of features for the predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14342d32-3b35-429d-908a-8b368e1c153e",
   "metadata": {},
   "source": [
    "##### When using the Wrapper method for feature selection in the context of predicting house prices, you typically apply a model-specific evaluation criterion to assess the importance of different feature subsets. Here's a step-by-step guide on how you might use the Wrapper method:\n",
    "\n",
    "1. Data Preparation:\n",
    "\n",
    "* Start by preparing your dataset, ensuring that it includes the target variable (house prices) and relevant features such as size, location, and age.\n",
    "\n",
    "2. Choose a Predictive Model:\n",
    "\n",
    "* Select a predictive model suitable for regression tasks. Common models for predicting house prices include linear regression, decision trees, random forests, or gradient boosting algorithms like XGBoost.\n",
    "\n",
    "3. Feature Scaling:\n",
    "\n",
    "* If necessary, scale or normalize numerical features to ensure that they have similar scales. This step is particularly important for models sensitive to feature scales, such as linear regression.\n",
    "\n",
    "4. Feature Subset Generation:\n",
    "\n",
    "* Use a search strategy to generate different subsets of features. Common strategies include forward selection, backward elimination, and recursive feature elimination (RFE). These strategies iteratively add or remove features based on their impact on model performance.\n",
    "\n",
    "5. Model Training and Evaluation:\n",
    "\n",
    "* Train the predictive model using each subset of features and evaluate its performance on a validation set. The evaluation metric should be chosen based on the nature of the regression problem. Common metrics include mean squared error (MSE), mean absolute error (MAE), or R-squared.\n",
    "\n",
    "6. Select Best Subset:\n",
    "\n",
    "* Choose the subset of features that resulted in the best model performance according to your chosen evaluation metric. This is your selected set of features for predicting house prices.\n",
    "7. Model Validation:\n",
    "\n",
    "* Validate the final predictive model using a separate test set to ensure its generalizability to new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccf1c392-cd98-43ce-85e7-fbd4fea33238",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\n`load_boston` has been removed from scikit-learn since version 1.2.\n\nThe Boston housing prices dataset has an ethical problem: as\ninvestigated in [1], the authors of this dataset engineered a\nnon-invertible variable \"B\" assuming that racial self-segregation had a\npositive impact on house prices [2]. Furthermore the goal of the\nresearch that led to the creation of this dataset was to study the\nimpact of air quality but it did not give adequate demonstration of the\nvalidity of this assumption.\n\nThe scikit-learn maintainers therefore strongly discourage the use of\nthis dataset unless the purpose of the code is to study and educate\nabout ethical issues in data science and machine learning.\n\nIn this special case, you can fetch the dataset from the original\nsource::\n\n    import pandas as pd\n    import numpy as np\n\n    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n    target = raw_df.values[1::2, 2]\n\nAlternative datasets include the California housing dataset and the\nAmes housing dataset. You can load the datasets as follows::\n\n    from sklearn.datasets import fetch_california_housing\n    housing = fetch_california_housing()\n\nfor the California housing dataset and::\n\n    from sklearn.datasets import fetch_openml\n    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n\nfor the Ames housing dataset.\n\n[1] M Carlisle.\n\"Racist data destruction?\"\n<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>\n\n[2] Harrison Jr, David, and Daniel L. Rubinfeld.\n\"Hedonic housing prices and the demand for clean air.\"\nJournal of environmental economics and management 5.1 (1978): 81-102.\n<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_boston\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/datasets/__init__.py:156\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_boston\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    106\u001b[0m     msg \u001b[38;5;241m=\u001b[39m textwrap\u001b[38;5;241m.\u001b[39mdedent(\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m        `load_boston` has been removed from scikit-learn since version 1.2.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     )\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()[name]\n",
      "\u001b[0;31mImportError\u001b[0m: \n`load_boston` has been removed from scikit-learn since version 1.2.\n\nThe Boston housing prices dataset has an ethical problem: as\ninvestigated in [1], the authors of this dataset engineered a\nnon-invertible variable \"B\" assuming that racial self-segregation had a\npositive impact on house prices [2]. Furthermore the goal of the\nresearch that led to the creation of this dataset was to study the\nimpact of air quality but it did not give adequate demonstration of the\nvalidity of this assumption.\n\nThe scikit-learn maintainers therefore strongly discourage the use of\nthis dataset unless the purpose of the code is to study and educate\nabout ethical issues in data science and machine learning.\n\nIn this special case, you can fetch the dataset from the original\nsource::\n\n    import pandas as pd\n    import numpy as np\n\n    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n    target = raw_df.values[1::2, 2]\n\nAlternative datasets include the California housing dataset and the\nAmes housing dataset. You can load the datasets as follows::\n\n    from sklearn.datasets import fetch_california_housing\n    housing = fetch_california_housing()\n\nfor the California housing dataset and::\n\n    from sklearn.datasets import fetch_openml\n    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n\nfor the Ames housing dataset.\n\n[1] M Carlisle.\n\"Racist data destruction?\"\n<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>\n\n[2] Harrison Jr, David, and Daniel L. Rubinfeld.\n\"Hedonic housing prices and the demand for clean air.\"\nJournal of environmental economics and management 5.1 (1978): 81-102.\n<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the Boston Housing dataset\n",
    "boston = load_boston()\n",
    "X = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "y = pd.Series(boston.target, name='target')\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Choose a predictive model (Random Forest Regressor in this case)\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Choose the search strategy (forward or backward)\n",
    "sfs = SequentialFeatureSelector(model, forward=True, k_features='best', scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "# Fit the feature selector to your training data\n",
    "sfs.fit(X_train, y_train)\n",
    "\n",
    "# Get the selected feature indices\n",
    "selected_feature_indices = list(sfs.k_feature_idx_)\n",
    "\n",
    "# Train the final model using the selected features\n",
    "final_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "final_model.fit(X_train.iloc[:, selected_feature_indices], y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = final_model.predict(X_test.iloc[:, selected_feature_indices])\n",
    "\n",
    "# Evaluate the model performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error on Test Set: {mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a4e018-d045-4702-a4fc-d27ae8511105",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
